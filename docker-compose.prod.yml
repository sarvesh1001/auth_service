version: '3.8'

services:
  # Go Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8443:8443"  # Changed from 8080 to 8443 for HTTPS
    environment:
      - ENVIRONMENT=production
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SCYLLA_NODES=scylla1,scylla2,scylla3
      - SCYLLA_USERNAME=${SCYLLA_USERNAME}
      - SCYLLA_PASSWORD=${SCYLLA_PASSWORD}
      - KAFKA_BROKERS=kafka:9093
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - JWT_SECRET=${JWT_SECRET}
      - API_KEY=${API_KEY}
    volumes:
      - ./certs:/root/certs:ro
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
    depends_on:
      redis:
        condition: service_healthy
      scylla1:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "https://localhost:8443/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis with Security
  redis:
    image: redis:7-alpine
    command: 
      - redis-server
      - --requirepass ${REDIS_PASSWORD}
      - --appendonly yes
      - --appendfsync everysec
      - --save 900 1
      - --save 300 10
      - --save 60 10000
    volumes:
      - redis_data_prod:/data
    deploy:
      replicas: 1
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    sysctls:
      - net.core.somaxconn=1024

  # ScyllaDB Cluster with Authentication
  scylla1:
    image: scylladb/scylla:5.2.0
    command: 
      - --seeds=scylla1,scylla2,scylla3
      - --memory 2G
      - --smp 2
      - --authenticator=PasswordAuthenticator
      - --authorizer=CassandraAuthorizer
    environment:
      - SCYLLA_CLUSTER_NAME=auth-cluster-prod
    volumes:
      - scylla1_data_prod:/var/lib/scylla
      - ./scripts/init-scylla.cql:/init-scylla.cql:ro
    deploy:
      replicas: 1
    healthcheck:
      test: ["CMD", "cqlsh", "-u", "${SCYLLA_USERNAME}", "-p", "${SCYLLA_PASSWORD}", "-e", "describe keyspaces"]
      interval: 30s
      timeout: 20s
      retries: 10
      start_period: 60s

  scylla2:
    image: scylladb/scylla:5.2.0
    command: 
      - --seeds=scylla1,scylla2,scylla3
      - --memory 2G
      - --smp 2
      - --authenticator=PasswordAuthenticator
      - --authorizer=CassandraAuthorizer
    environment:
      - SCYLLA_CLUSTER_NAME=auth-cluster-prod
    volumes:
      - scylla2_data_prod:/var/lib/scylla
    deploy:
      replicas: 1
    depends_on:
      - scylla1

  scylla3:
    image: scylladb/scylla:5.2.0
    command: 
      - --seeds=scylla1,scylla2,scylla3
      - --memory 2G
      - --smp 2
      - --authenticator=PasswordAuthenticator
      - --authorizer=CassandraAuthorizer
    environment:
      - SCYLLA_CLUSTER_NAME=auth-cluster-prod
    volumes:
      - scylla3_data_prod:/var/lib/scylla
    deploy:
      replicas: 1
    depends_on:
      - scylla1

  # Kafka + Zookeeper with Security
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_ADMIN_ENABLE_SERVER: false
    deploy:
      replicas: 1

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:SASL_PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SASL_PLAINTEXT
    deploy:
      replicas: 1
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5

  # Elasticsearch with Security
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - xpack.license.self_generated.type=basic
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.http.ssl.enabled=false
    volumes:
      - elasticsearch_data_prod:/usr/share/elasticsearch/data
    deploy:
      replicas: 1
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:${ELASTIC_PASSWORD} http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    ulimits:
      memlock:
        soft: -1
        hard: -1

  # Kibana with Security
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - XPACK_SECURITY_ENABLED=true
    deploy:
      replicas: 1
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ClickHouse with Security
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      - CLICKHOUSE_DB=auth_service
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse_data_prod:/var/lib/clickhouse
      - ./scripts/clickhouse-users.xml:/etc/clickhouse-server/users.d/users.xml:ro
    deploy:
      replicas: 1
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  redis_data_prod:
    driver: local
  scylla1_data_prod:
    driver: local
  scylla2_data_prod:
    driver: local
  scylla3_data_prod:
    driver: local
  elasticsearch_data_prod:
    driver: local
  clickhouse_data_prod:
    driver: local

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 10.200.0.0/24